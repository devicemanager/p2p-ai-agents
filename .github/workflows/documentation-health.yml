name: ðŸ“Š Documentation Health Dashboard

on:
  push:
    branches: [main, master]
    paths:
      - 'docs/**'
      - '.github/workflows/documentation-*.yml'
  schedule:
    # Daily health check at 06:00 UTC
    - cron: '0 6 * * *'
  workflow_dispatch:

jobs:
  health-check:
    name: ðŸ“Š Documentation Health Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: ðŸ“Š Analyze Documentation Health
      run: |
        echo "ðŸ“Š Analyzing documentation health..."
        
        # Create comprehensive health report
        cat > health_analysis.py << 'EOF'
        #!/usr/bin/env python3
        import os
        import re
        import json
        from pathlib import Path
        from datetime import datetime, timedelta

        def analyze_documentation():
            docs_dir = Path("docs")
            results = {
                "timestamp": datetime.now().isoformat(),
                "total_files": 0,
                "health_score": 0,
                "issues": [],
                "metrics": {},
                "recommendations": []
            }
            
            # Count files and analyze content
            md_files = list(docs_dir.rglob("*.md"))
            results["total_files"] = len(md_files)
            
            # Metrics tracking
            metrics = {
                "files_with_version": 0,
                "files_with_todos": 0,
                "files_with_placeholders": 0,
                "broken_links": 0,
                "outdated_files": 0,
                "total_lines": 0
            }
            
            issues = []
            
            for file_path in md_files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                metrics["total_lines"] += len(content.splitlines())
                
                # Check for version info
                if "Current Version:" in content:
                    metrics["files_with_version"] += 1
                    
                # Check for TODOs/placeholders
                if re.search(r'TODO|FIXME|\[PLACEHOLDER\]|\[DESCRIPTION NEEDED\]', content):
                    metrics["files_with_todos"] += 1
                    issues.append(f"Incomplete content in {file_path}")
                    
                # Check for old timestamps (older than 6 months)
                last_updated_match = re.search(r'Last Updated: (\d{4}-\d{2}-\d{2})', content)
                if last_updated_match:
                    date_str = last_updated_match.group(1)
                    file_date = datetime.strptime(date_str, "%Y-%m-%d")
                    if datetime.now() - file_date > timedelta(days=180):
                        metrics["outdated_files"] += 1
                        issues.append(f"Outdated file (>6 months): {file_path}")
                        
                # Basic link validation
                links = re.findall(r'\[([^\]]*)\]\(([^)]+\.md)\)', content)
                for link_text, link_url in links:
                    if not link_url.startswith(('http', '#')):
                        # Check relative links
                        if link_url.startswith('../'):
                            target = file_path.parent / link_url
                        else:
                            target = file_path.parent / link_url
                            
                        try:
                            if not target.resolve().exists():
                                metrics["broken_links"] += 1
                                issues.append(f"Broken link in {file_path}: {link_url}")
                        except:
                            pass
            
            results["metrics"] = metrics
            results["issues"] = issues[:20]  # Limit to first 20 issues
            
            # Calculate health score (0-100)
            total_checks = results["total_files"] * 4  # 4 checks per file
            issues_count = len(issues)
            health_score = max(0, 100 - (issues_count / total_checks * 100)) if total_checks > 0 else 100
            results["health_score"] = round(health_score)
            
            # Generate recommendations
            recommendations = []
            if metrics["files_with_todos"] > 0:
                recommendations.append(f"Complete {metrics['files_with_todos']} files with TODO/placeholder content")
            if metrics["broken_links"] > 0:
                recommendations.append(f"Fix {metrics['broken_links']} broken internal links")
            if metrics["outdated_files"] > 0:
                recommendations.append(f"Update {metrics['outdated_files']} outdated files")
            if metrics["files_with_version"] < results["total_files"] * 0.8:
                recommendations.append("Add version information to more documentation files")
                
            results["recommendations"] = recommendations
            
            return results

        # Run analysis
        results = analyze_documentation()

        # Output results
        print(f"ðŸ“Š Documentation Health Score: {results['health_score']}/100")
        print(f"ðŸ“ Total Files: {results['total_files']}")
        print(f"ðŸ“ Total Lines: {results['metrics']['total_lines']}")
        print(f"âš ï¸  Issues Found: {len(results['issues'])}")

        # Save detailed results
        with open('health_report.json', 'w') as f:
            json.dump(results, f, indent=2)

        # Create markdown report
        with open('health_report.md', 'w') as f:
            f.write(f"# ðŸ“Š Documentation Health Report\n\n")
            f.write(f"**Generated**: {results['timestamp']}\n")
            f.write(f"**Health Score**: {results['health_score']}/100\n\n")
            
            f.write(f"## ðŸ“ˆ Metrics\n")
            f.write(f"- **Total Files**: {results['total_files']}\n")
            f.write(f"- **Total Lines**: {results['metrics']['total_lines']}\n")
            f.write(f"- **Files with Version Info**: {results['metrics']['files_with_version']}\n")
            f.write(f"- **Files with TODOs**: {results['metrics']['files_with_todos']}\n")
            f.write(f"- **Broken Links**: {results['metrics']['broken_links']}\n")
            f.write(f"- **Outdated Files**: {results['metrics']['outdated_files']}\n\n")
            
            if results['issues']:
                f.write(f"## âš ï¸ Issues ({len(results['issues'])})\n")
                for issue in results['issues'][:10]:
                    f.write(f"- {issue}\n")
                if len(results['issues']) > 10:
                    f.write(f"- ... and {len(results['issues']) - 10} more\n")
                f.write("\n")
                
            if results['recommendations']:
                f.write(f"## ðŸ’¡ Recommendations\n")
                for rec in results['recommendations']:
                    f.write(f"- {rec}\n")
                f.write("\n")
                
            f.write("---\n*Generated by Documentation Health Monitor ðŸ¤–*\n")

        EOF
        
        python health_analysis.py
        
    - name: ðŸ“ˆ Generate Health Badge
      run: |
        # Read health score
        health_score=$(python -c "import json; print(json.load(open('health_report.json'))['health_score'])")
        
        # Determine badge color
        if [ $health_score -ge 80 ]; then
          color="brightgreen"
          status="excellent"
        elif [ $health_score -ge 60 ]; then
          color="yellow"
          status="good"
        elif [ $health_score -ge 40 ]; then
          color="orange"
          status="needs-work"
        else
          color="red"
          status="critical"
        fi
        
        echo "Health Score: $health_score ($status)"
        echo "HEALTH_SCORE=$health_score" >> $GITHUB_ENV
        echo "HEALTH_STATUS=$status" >> $GITHUB_ENV
        echo "BADGE_COLOR=$color" >> $GITHUB_ENV
        
    - name: ðŸ“Š Create Health Summary
      run: |
        cat > health_summary.md << EOF
        ## ðŸ“Š Documentation Health Summary
        
        **Score**: ${{ env.HEALTH_SCORE }}/100 (${{ env.HEALTH_STATUS }})
        **Date**: $(date)
        **Repository**: ${{ github.repository }}
        
        ### Quick Stats
        - ðŸ“ Total documentation files: $(find docs -name "*.md" | wc -l)
        - ðŸ“ Total lines of documentation: $(find docs -name "*.md" -exec wc -l {} + | tail -1 | awk '{print $1}')
        - ðŸ”— Internal links checked: $(grep -r "]\(.*\.md\)" docs/ --include="*.md" | wc -l || echo "0")
        
        ### Health Trend
        ![Health Badge](https://img.shields.io/badge/docs%20health-${{ env.HEALTH_SCORE }}%25-${{ env.BADGE_COLOR }})
        
        ---
        *View detailed report in the workflow artifacts*
        EOF
        
    - name: ðŸ“¤ Upload Health Reports
      uses: actions/upload-artifact@v4
      with:
        name: documentation-health-report
        path: |
          health_report.json
          health_report.md
          health_summary.md
        retention-days: 30
        
    - name: ðŸ’¬ Comment on PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const healthSummary = fs.readFileSync('health_summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: healthSummary
          });
          
    - name: ðŸš¨ Create Issue for Low Health Score
      if: env.HEALTH_SCORE < 60
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const healthReport = fs.readFileSync('health_report.md', 'utf8');
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `ðŸ“Š Documentation Health Score Below 60% (${process.env.HEALTH_SCORE}/100)`,
            body: `## ðŸš¨ Documentation Health Alert
            
            The documentation health score has fallen below the recommended threshold.
            
            **Current Score**: ${process.env.HEALTH_SCORE}/100
            **Status**: ${process.env.HEALTH_STATUS}
            
            ${healthReport}
            
            **Recommended Actions**:
            1. Run the maintenance workflow: \`workflow_dispatch\` on \`documentation-maintenance.yml\`
            2. Review and fix the issues listed above
            3. Consider updating outdated documentation
            
            This issue will be automatically closed when the health score improves.`,
            labels: ['documentation', 'health-check', 'priority-medium']
          });
          
    - name: âœ… Close Health Issue if Score Improved
      if: env.HEALTH_SCORE >= 60
      uses: actions/github-script@v7
      with:
        script: |
          // Find and close health-related issues if score is good
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'health-check',
            state: 'open'
          });
          
          for (const issue of issues.data) {
            if (issue.title.includes('Documentation Health Score Below')) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issue.number,
                body: `âœ… Documentation health has improved to ${process.env.HEALTH_SCORE}/100. Closing this issue.`
              });
              
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issue.number,
                state: 'closed'
              });
            }
          }
